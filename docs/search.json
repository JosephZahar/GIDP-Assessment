[
  {
    "objectID": "index.html#basic-stats",
    "href": "index.html#basic-stats",
    "title": "R skills assessment",
    "section": "Basic Stats",
    "text": "Basic Stats\n\n1. Summary statistics of GDP per capita by region\n\n# Defining a function to calculate weighted standard deviation\nweighted_sd &lt;- function(x, pop) {\n  # Calculating the weighted mean of the squared differences from the mean\n  # x: a numeric vector\n  # pop: weights for the elements in x\n  sqrt(weighted.mean((x - weighted.mean(x, pop, na.rm = TRUE))^2, \n                     pop, na.rm = TRUE))\n}\n\n# Summarize GDP data with weighted standard deviation, min, max, and count of non-NA values\ngdp_sum &lt;- wdi[, .(\n  N = sum(!is.na(gdp)),                    # Count of non-NA GDP values\n  Mean = weighted.mean(gdp, pop),         # Weighted mean of GDP\n        SD = weighted_sd(gdp, pop),       # Weighted standard deviation of GDP\n  Min = min(gdp, na.rm = TRUE),            # Minimum GDP value, excluding NAs\n  Max = max(gdp, na.rm = TRUE)             # Maximum GDP value, excluding NAs\n), by = .(region, date)]                   # Grouping by region and date\n\n# Order the resulting data table by region and date\nsetorder(gdp_sum, region, date)\n\n# Rename the 'date' column to 'year'\nsetnames(gdp_sum, \"date\", \"year\")\n\n# Load the reference dataset for comparison\ncorrect_q1 &lt;- readr::read_rds(paste0(data_url, \"wdi_summ_out.Rds\"))\n\n# Compare the computed summary with the reference summary (commented out)\n# waldo::compare(correct_q1, gdp_sum)\n\n# Display the summarized data table\ndatatable(gdp_sum, options = list(pageLength = 10))\n\n\n\n\n\n\n\n\n2. Aggregate Stats\n\n# Calculate aggregated statistics for life expectancy, GDP, and international poverty\nagg_stats &lt;- wdi[, .(\n  mean_lifeex = weighted.mean(lifeex, pop, na.rm = TRUE),     # Weighted mean of life expectancy\n  sd_lifeex = weighted_sd(lifeex, pop),                        # Weighted standard deviation of life expectancy\n  min_lifeex = min(lifeex, na.rm = TRUE),                      # Minimum life expectancy, excluding NAs\n  max_lifeex = max(lifeex, na.rm = TRUE),                      # Maximum life expectancy, excluding NAs\n  median_lifeex = weighted.median(lifeex, pop, na.rm = TRUE),  # Weighted median of life expectancy\n\n  mean_gdp = weighted.mean(gdp, pop, na.rm = TRUE),            # Weighted mean of GDP\n  sd_gdp = weighted_sd(gdp, pop),                              # Weighted standard deviation of GDP\n  min_gdp = min(gdp, na.rm = TRUE),                            # Minimum GDP value, excluding NAs\n  max_gdp = max(gdp, na.rm = TRUE),                            # Maximum GDP value, excluding NAs\n  median_gdp = weighted.median(gdp, pop, na.rm = TRUE),        # Weighted median of GDP\n\n  mean_pov_intl = weighted.mean(pov_intl, pop, na.rm = TRUE),  # Weighted mean of international poverty\n  sd_pov_intl = weighted_sd(pov_intl),                         # Weighted standard deviation of international poverty\n  min_pov_intl = min(pov_intl, na.rm = TRUE),                  # Minimum international poverty, excluding NAs\n  max_pov_intl = max(pov_intl, na.rm = TRUE),                  # Maximum international poverty, excluding NAs\n  median_pov_intl = weighted.median(pov_intl, pop, na.rm = TRUE), # Weighted median of international poverty\n\n  pop = sum(pop, na.rm = TRUE)                                 # Sum of population, excluding NAs\n),\nby = .(region, date)                                           # Grouping by region and date\n]\n\n# Reshape the data from wide to long format\nagg_stats &lt;- melt(agg_stats,\n  id.vars = c(\"region\", \"date\", \"pop\"),                        # Identifying variables\n  measure.vars = list(\n    c(\"mean_lifeex\", \"sd_lifeex\", \"min_lifeex\", \"max_lifeex\", \"median_lifeex\"),\n    c(\"mean_gdp\", \"sd_gdp\", \"min_gdp\", \"max_gdp\", \"median_gdp\"),\n    c(\"mean_pov_intl\", \"sd_pov_intl\", \"min_pov_intl\", \"max_pov_intl\", \n      \"median_pov_intl\")\n  ),\n  variable.name = \"estimate\", value.name = c(\"lifeex\", \"gdp\", \"pov_intl\")\n)\n\n# Convert 'estimate' column to a factor with meaningful labels\nagg_stats[, estimate := factor(estimate, labels = c(\"mean\", \"sd\", \"min\", \"max\", \n                                                    \"median\"))]\n\n# Order the data table by estimate, region, and date\nsetorder(agg_stats, estimate, region, date)\n\n# Reorder columns for better readability\nagg_stats &lt;- agg_stats[, c(4, 1, 2, 3, 5, 6, 7)]\n\n# Load the reference dataset for comparison\ncorrect_q2 &lt;- readr::read_rds(paste0(data_url, \"wdi_agg_out.Rds\"))\n\n# Compare the computed aggregate stats with the reference dataset (commented out)\n# waldo::compare(correct_q2, agg_stats)\n\n# Display the aggregated data \ndatatable(agg_stats, options = list(pageLength = 10))\n\n\n\n\n\n\n\n\n3. Find outliers\n\n# Defining a function to identify outlier columns in a data table\nis_outlier_cols &lt;- function(dt, col) {\n  # Creating column names for lower and higher limits, mean and standard deviation\n  new_col_ll &lt;- paste0(\"ll_\", col)  # Lower limit column name\n  new_col_hl &lt;- paste0(\"hl_\", col)  # Higher limit column name\n  mean_col &lt;- paste0(\"mean_\", col)  # Mean column name\n  sd_col &lt;- paste0(\"sd_\", col)      # Standard deviation column name\n\n  # Find limit outliers\n  dt[, (new_col_ll) := get(col) &lt; get(mean_col) - 2.5 * get(sd_col), \n     by = 1:nrow(dt)]\n\n  # Find higher limit outliers\n  dt[, (new_col_hl) := get(col) &gt; get(mean_col) + 2.5 * get(sd_col), \n     by = 1:nrow(dt)]\n\n  return(dt)\n}\n\n# Calculate mean and standard deviation for life expectancy, GDP, and Gini index\ntemp_dt &lt;- wdi[, .(\n  mean_lifeex = weighted.mean(lifeex, pop, na.rm = TRUE),  # Weighted Mean life expectancy\n  sd_lifeex = weighted_sd(lifeex, pop),                    # Weighted SD of life expectancy\n  mean_gdp = weighted.mean(gdp, pop, na.rm = TRUE),        # Weighted Mean GDP\n  sd_gdp = weighted_sd(gdp, pop),                          # Weighted SD of GDP\n  mean_gini = weighted.mean(gini, pop, na.rm = TRUE),      # Weighted Mean Gini index\n  sd_gini = weighted_sd(gini, pop)                         # Weighted SD of Gini index\n), by = .(date)]\n\n# Merge the summary statistics with the original dataset (right join)\noutliers_dt &lt;- merge(y = temp_dt, x = wdi, by = c(\"date\"), all.x = TRUE)\n\n# Order the merged data table\nsetorder(outliers_dt, iso3c, date, -region)\n\n# Apply the outlier detection function to specified columns\nfor (col in c(\"lifeex\", \"gdp\", \"gini\")) {\n  outliers_dt &lt;- is_outlier_cols(outliers_dt, col)\n}\n\n# Load the reference dataset for comparison\ncorrect_q3 &lt;- readr::read_rds(paste0(data_url, \"wdi_outliers_out.Rds\"))\n\n# Reorder the columns to be the same as the reference dataset\noutliers_dt &lt;- outliers_dt[, colnames(correct_q3), with = FALSE]\n\n# Compare the computed outlier data with a reference dataset (commented out)\n# waldo::compare(correct_q3, outliers_dt)\n\n# Display the outliers data \ndatatable(outliers_dt, options = list(pageLength = 10))\n\n\n\n\n\n\n\n# Defining a function to create columns for lower and upper confidence intervals\noutlier_cols &lt;- function(dt, col) {\n  # Creating new column names for lower and upper confidence intervals\n  new_col_ll &lt;- paste0(\"lo_ci_\", col)  # Lower confidence interval column name\n  new_col_hl &lt;- paste0(\"hi_ci_\", col)  # Upper confidence interval column name\n  mean_col &lt;- paste0(\"mean_\", col)     # Mean column name\n  sd_col &lt;- paste0(\"sd_\", col)         # Standard deviation column name\n\n  # Calculate lower confidence interval for each row\n  dt[, (new_col_ll) := get(mean_col) - 2.5 * get(sd_col), by = 1:nrow(dt)]\n\n  # Calculate upper confidence interval for each row\n  dt[, (new_col_hl) := get(mean_col) + 2.5 * get(sd_col), by = 1:nrow(dt)]\n\n  return(dt)\n}\n\n# Apply the function to the 'lifeex' column of the 'outliers_dt' data table\n# and remove duplicate rows based on date and confidence interval columns\noutliers_dt_2 &lt;- unique(outlier_cols(outliers_dt, \"lifeex\"), \n                        by = c(\"date\", \"lo_ci_lifeex\", \"hi_ci_lifeex\"))\n\n# Create a plot using ggplot2\n# plotting points of original table containing data from all regions\nggplot(data = outliers_dt, aes(x = date, y = lifeex)) +\n  # Add a ribbon to show confidence intervals using the table with unique values\n  geom_ribbon(data = outliers_dt_2, aes(x = date, ymin = lo_ci_lifeex, \n                                        ymax = hi_ci_lifeex), alpha = 0.2) +\n  # Add points for each observation, colored by region\n  geom_point(aes(color = region), size = 0.8) +\n  # Add a line to show the mean life expectancy over time\n  geom_line(aes(x = date, y = mean_lifeex), color = \"blue\", linewidth = 0.2) +\n  theme_minimal() +\n  # Customize the legend and plot theme\n  theme(\n    legend.position = c(0.5, 0.1),\n    legend.justification = c(0.5, 0),\n    legend.direction = \"horizontal\",\n    legend.title = element_blank(),\n    legend.background = element_blank(),\n    legend.box.background = element_blank()\n  )"
  },
  {
    "objectID": "index.html#simulated-data",
    "href": "index.html#simulated-data",
    "title": "R skills assessment",
    "section": "Simulated data",
    "text": "Simulated data\n\n4. Poverty measures\n\n# Initialize an empty data table for poverty metrics with predefined columns\ncols &lt;- c(\"year\", \"pov_line\", \"headcount\", \"povgap\", \"povseverity\")\npov_dt &lt;- data.table(matrix(ncol = length(cols), nrow = 0))\nsetnames(pov_dt, cols)\n\n# Defining a function to calculate the Foster-Greer-Thorbecke (FGT) poverty measures\nFGT &lt;- function(pov_line, year, dt) {\n  # Total population weight\n  N &lt;- sum(dt$weight)\n  # Calculate part of FGTi \n  dt[, `:=`(FGTi = (pov_line - income) / pov_line)]\n  # Subset data for those below the poverty line\n  dt_subset &lt;- dt[income &lt;= pov_line]\n  # Calculate FGT indexes: headcount ratio, poverty gap, and severity of poverty\n  FGT0 &lt;- sum(dt_subset$weight * dt_subset$FGTi^0) / N\n  FGT1 &lt;- sum(dt_subset$weight * dt_subset$FGTi^1) / N\n  FGT2 &lt;- sum(dt_subset$weight * dt_subset$FGTi^2) / N\n\n  # Create a new data table with calculated values\n  new_data &lt;- data.table(year = year, pov_line = pov_line, headcount = FGT0, \n                         povgap = FGT1, povseverity = FGT2)\n  # Append new data to the pov_dt data table\n  pov_dt &lt;&lt;- rbindlist(list(pov_dt, new_data), use.names = TRUE, fill = TRUE)\n}\n\n# Start year for the analysis\nyear &lt;- 2001\n# Loop through survey simulation datasets for each year\nfor (dt in svy_sim) {\n  # Apply the FGT function for different poverty lines\n  FGT(2.15, year, dt)\n  FGT(3.65, year, dt)\n  FGT(6.85, year, dt)\n  # Increment the year\n  year &lt;- year + 1\n}\n\n# Load the reference dataset for comparison\ncorrect_q4 &lt;- readr::read_rds(paste0(data_url, \"dt_pov_out.Rds\"))\n# Compare the computed poverty data with the reference dataset (commented out)\n# waldo::compare(correct_q4, pov_dt)\n# Display the poverty data \ndatatable(pov_dt, options = list(pageLength = 10))\n\n\n\n\n\n\n\n# Create a line plot using ggplot2 to visualize poverty metrics over years\nggplot(data = pov_dt, aes(x = year, y = headcount, group = pov_line, \n                          color = as.factor(pov_line))) +\n  geom_line(linewidth = 0.5) +  # Line for each poverty line\n  geom_point(size = 0.8) +      # Points for each year and poverty line\n  theme_minimal() +           \n  # Customizing the legend and plot appearance\n  theme(\n    legend.position = \"bottom\",\n    legend.direction = \"horizontal\",\n    legend.title = element_blank(),\n    legend.background = element_blank(),\n    legend.box.background = element_blank()\n  )\n\n\n\n\n\n\n5. Lorenz curve\n\n# Initialize an empty data table for Lorenz curve data with specified columns\ncols &lt;- c(\"welfare\", \"cum_welfare\", \"cum_population\", \"year\", \"bin\")\nlorenz_dt &lt;- data.table(matrix(ncol = length(cols), nrow = 0))\nsetnames(lorenz_dt, cols)\n\n# Defining a function to calculate and store Lorenz curve data\nLorenz &lt;- function(dt, year) {\n  # Sort the data table by income\n  dt &lt;- dt[order(dt$income), ]\n  # Calculate cumulative population and welfare (income) shares\n  dt$cum_pop &lt;- cumsum(dt$weight) / sum(dt$weight)\n  dt$cum_welfare &lt;- cumsum(dt$weight * dt$income) / sum(dt$weight * dt$income)\n  dt$welfare &lt;- cumsum(dt$weight * dt$income)\n\n  # Interpolate to get a smooth Lorenz curve with 100 points\n  approx_points &lt;- approx(dt$cum_pop, dt$cum_welfare, n = 100)\n  # Map each interpolated population share to an income value\n  income_val &lt;- sapply(approx_points$x, function(x) {\n    idx &lt;- which.min(abs(dt$cum_pop - x))\n    return(dt$income[idx])\n  })\n\n  # Create a new data frame with interpolated Lorenz curve data\n  new_data &lt;- data.frame(welfare = income_val, cum_welfare = approx_points$y, \n                         cum_population = approx_points$x, year = year, bin = 1:100)\n  # Append the new data to the global Lorenz curve data table\n  lorenz_dt &lt;&lt;- rbindlist(list(lorenz_dt, new_data), use.names = TRUE, \n                          fill = TRUE)\n}\n\n# Initialize the starting year for analysis\nyear &lt;- 2001\n# Loop through survey simulation datasets for each year\nfor (dt in svy_sim) {\n  Lorenz(dt, year)\n  year &lt;- year + 1\n}\n\n# Load the reference dataset for comparison\ncorrect_q5 &lt;- readr::read_rds(paste0(data_url, \"dt_lorenz_out.Rds\"))\n# Compare the computed Lorenz curve data with the reference dataset (commented out)\n# waldo::compare(correct_q4, pov_dt)\n# Display the Lorenz curve data \ndatatable(lorenz_dt, options = list(pageLength = 10))\n\n\n\n\n\n\n\n# Create a line plot using ggplot2 to visualize Lorenz curves over years\nggplot(data = lorenz_dt, aes(x = cum_population, y = cum_welfare, group = year, \n                             color = as.factor(year))) +\n  geom_line(linewidth = 0.4) +  # Line for each year\n  theme_minimal() +             \n  # Customize the legend and plot appearance\n  theme(\n    legend.position = c(0.1, 0.2),\n    legend.justification = c(0.5, 0),\n    legend.direction = \"vertical\",\n    legend.title = element_blank(),\n    legend.background = element_blank(),\n    legend.box.background = element_blank()\n  )\n\n\n\n\n\n\n6. Gini coefficient\n\n# Initialize an empty data table for storing Gini coefficient data\ncols &lt;- c(\"year\", \"gini\")\ngini_dt &lt;- data.table(matrix(ncol = length(cols), nrow = 0))\nsetnames(gini_dt, cols)\n\n# Defining a function to calculate the Gini coefficient\nGini &lt;- function(dt, years) {\n  # Filter data for the specific year\n  dt &lt;- dt[year == years]\n  # Order the data table by 'bin'\n  setorder(dt, bin)\n  # Initialize area accumulator\n  A &lt;- 0\n  # Loop to calculate the area under the Lorenz curve\n  for (i in 2:length(dt$cum_pop)) {\n    width &lt;- dt$cum_pop[i] - dt$cum_pop[i - 1]  # Width of the segment\n    height_avg &lt;- (dt$cum_welfare[i] + dt$cum_welfare[i - 1]) / 2  # Average height of the segment\n    A &lt;- A + (width * height_avg)  # Accumulate area\n  }\n\n  # Calculate Gini index\n  gini_index &lt;- 1 - 2 * A\n  # Create a new data frame with the calculated Gini index\n  new_data &lt;- data.frame(year = years, gini = gini_index)\n  # Append the new data to the global Gini data table\n  gini_dt &lt;&lt;- rbindlist(list(gini_dt, new_data), use.names = TRUE, fill = TRUE)\n}\n\n# Initialize the starting year for analysis\nyear &lt;- 2001\n# Loop to calculate Gini coefficient for multiple years\nfor (i in 1:10) {\n  Gini(lorenz_dt, year)\n  year &lt;- year + 1\n}\n\n# Load the reference dataset for comparison\ncorrect_q6 &lt;- readr::read_rds(paste0(data_url, \"dt_gini_out.Rds\"))\n# Compare the computed Gini data with the reference dataset (commented out)\n# waldo::compare(correct_q6, gini_dt)\n# Display the Gini data\ndatatable(gini_dt, options = list(pageLength = 10))\n\n\n\n\n\n\n\n# Create a line plot using ggplot2 to visualize the Gini coefficient over years\nggplot(data = gini_dt, aes(x = year, y = gini)) +\n  geom_line(linewidth = 0.4) +  # Line showing the trend of the Gini coefficient\n  geom_point(size = 0.8) +      # Points for each year\n  theme_minimal()"
  }
]